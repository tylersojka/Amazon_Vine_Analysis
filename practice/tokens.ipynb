{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tokens","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMAGN+QZE9Jxebt6Rzhio+L"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kRF-14YFIMUF","executionInfo":{"status":"ok","timestamp":1610027739497,"user_tz":360,"elapsed":21639,"user":{"displayName":"Tyler Sojka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuSAFevUJa1gRZWtVga-ccYOTrGdu2lTxCmKUzcw=s64","userId":"11402974615608992588"}},"outputId":"b9af4225-d530-4196-c82f-988e6fb1cf12"},"source":["import os\n","# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.1'\n","spark_version = 'spark-3.0.1'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rGet:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.39)] [Co\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [Connecting to security.ubuntu.com (91.189.91.39)] [Connected to cloud.r-pro\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","\r0% [3 InRelease 47.5 kB/88.7 kB 54%] [Connecting to security.ubuntu.com (91.189\r                                                                               \rHit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r0% [3 InRelease 47.5 kB/88.7 kB 54%] [Connecting to security.ubuntu.com (91.189\r                                                                               \rGet:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","\r0% [3 InRelease 47.5 kB/88.7 kB 54%] [Connecting to security.ubuntu.com (91.189\r0% [2 InRelease gpgv 242 kB] [3 InRelease 47.5 kB/88.7 kB 54%] [Connecting to s\r0% [2 InRelease gpgv 242 kB] [3 InRelease 47.5 kB/88.7 kB 54%] [Connecting to s\r0% [2 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rHit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Get:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n","Get:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n","Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,707 kB]\n","Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [874 kB]\n","Get:16 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [42.7 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,140 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,274 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [277 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [53.3 kB]\n","Get:22 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [66.5 kB]\n","Get:23 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,376 kB]\n","Get:24 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [14.9 kB]\n","Get:25 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,846 kB]\n","Get:26 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [247 kB]\n","Fetched 11.2 MB in 3s (3,858 kB/s)\n","Reading package lists... Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nw4vjlkoIT_G","executionInfo":{"status":"ok","timestamp":1610028380089,"user_tz":360,"elapsed":8488,"user":{"displayName":"Tyler Sojka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuSAFevUJa1gRZWtVga-ccYOTrGdu2lTxCmKUzcw=s64","userId":"11402974615608992588"}}},"source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"o0E9Kg5KK05Q","executionInfo":{"status":"ok","timestamp":1610030428713,"user_tz":360,"elapsed":1101,"user":{"displayName":"Tyler Sojka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuSAFevUJa1gRZWtVga-ccYOTrGdu2lTxCmKUzcw=s64","userId":"11402974615608992588"}}},"source":["from pyspark.ml.feature import Tokenizer"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"slMp8nynSq2Y","executionInfo":{"status":"ok","timestamp":1610031123377,"user_tz":360,"elapsed":903,"user":{"displayName":"Tyler Sojka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuSAFevUJa1gRZWtVga-ccYOTrGdu2lTxCmKUzcw=s64","userId":"11402974615608992588"}},"outputId":"253db0a0-a76c-4248-f601-87efc1ff8f4e"},"source":["# create a sample dataFrame\n","dataframe = spark.createDataFrame([\n","    (0, \"Spark is great\"),\n","    (1, \"We are learning Spark\"),\n","    (2, \"Spark is better than hadoop no doubt\")                                  \n","], ['id', 'sentence'])\n","dataframe.show(truncate= False)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+\n","|id |sentence                            |\n","+---+------------------------------------+\n","|0  |Spark is great                      |\n","|1  |We are learning Spark               |\n","|2  |Spark is better than hadoop no doubt|\n","+---+------------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmZKGuYkUgs4","executionInfo":{"status":"ok","timestamp":1610030994840,"user_tz":360,"elapsed":736,"user":{"displayName":"Tyler Sojka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuSAFevUJa1gRZWtVga-ccYOTrGdu2lTxCmKUzcw=s64","userId":"11402974615608992588"}},"outputId":"78e7211a-e057-4cd1-a8b8-854ddb91d018"},"source":["# tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","tokenizer"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer_60c92abd77f2"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WhthJkbUU1Jr","executionInfo":{"status":"ok","timestamp":1610031109526,"user_tz":360,"elapsed":1709,"user":{"displayName":"Tyler Sojka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuSAFevUJa1gRZWtVga-ccYOTrGdu2lTxCmKUzcw=s64","userId":"11402974615608992588"}},"outputId":"70d9df6e-799a-4bca-92ef-96fe6a794e99"},"source":["# transform and show Dataframe\n","tokenized_df = tokenizer.transform(dataframe)\n","tokenized_df.show(truncate = False)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+\n","|id |sentence                            |words                                       |\n","+---+------------------------------------+--------------------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |\n","|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|\n","+---+------------------------------------+--------------------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aFG_y7DdVQ69","executionInfo":{"status":"ok","timestamp":1610031236393,"user_tz":360,"elapsed":669,"user":{"displayName":"Tyler Sojka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuSAFevUJa1gRZWtVga-ccYOTrGdu2lTxCmKUzcw=s64","userId":"11402974615608992588"}}},"source":["#create a function to return the length of a list\n","def word_list_length(word_list):\n","  return len(word_list)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"cAAXijzPVwI-","executionInfo":{"status":"ok","timestamp":1610031276045,"user_tz":360,"elapsed":508,"user":{"displayName":"Tyler Sojka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuSAFevUJa1gRZWtVga-ccYOTrGdu2lTxCmKUzcw=s64","userId":"11402974615608992588"}}},"source":["from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"eXbsNplYV53i","executionInfo":{"status":"ok","timestamp":1610031355941,"user_tz":360,"elapsed":844,"user":{"displayName":"Tyler Sojka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuSAFevUJa1gRZWtVga-ccYOTrGdu2lTxCmKUzcw=s64","userId":"11402974615608992588"}}},"source":["# create a user defined function (UDF)\n","count_tokens = udf(word_list_length, IntegerType())"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zDYYsVZdWNSr","executionInfo":{"status":"ok","timestamp":1610031544594,"user_tz":360,"elapsed":1665,"user":{"displayName":"Tyler Sojka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuSAFevUJa1gRZWtVga-ccYOTrGdu2lTxCmKUzcw=s64","userId":"11402974615608992588"}},"outputId":"0d134f29-fac8-46fc-82a3-48bd29aa9391"},"source":["# create our tokenizer\n","tokenizer = Tokenizer(inputCol = \"sentence\", outputCol= \"words\")\n","\n","# transform dataframe \n","tokenized_df = tokenizer.transform(dataframe)\n","\n","# select the need columns and dont truncate the results\n","tokenized_df.withColumn(\"tokens\", count_tokens(col(\"words\"))).show(truncate = False)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |words                                       |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is great                      |[spark, is, great]                          |3     |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |4     |\n","|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UDNLaeM-W7Jl"},"source":[""],"execution_count":null,"outputs":[]}]}